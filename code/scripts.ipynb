{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26288784"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = [0.35611578, 0.17192982, 0.26067516, 0.27556883, 0.25014961]\n",
    "np.mean(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200619S184-2BL-1.csv\n",
      "20200705S190BL-1.csv\n",
      "20200801S202BL-2.csv\n",
      "20200804S195AL-2.csv\n",
      "20200804S196AL-1.csv\n",
      "20200805S200AL-1.csv\n",
      "20200818S214AL-1.csv\n",
      "20200819S221AL-1.csv\n",
      "EP040_BL-1.csv\n",
      "EP046_BL-1.csv\n",
      "EP062-AL-1.csv\n",
      "EP081_AL-1.csv\n",
      "EP081_BL-1.csv\n",
      "EP082_AL-1.csv\n",
      "EP083_BL-1.csv\n",
      "EP084_BL-1.csv\n",
      "EP091_BL-1.csv\n",
      "EP097_AL-1.csv\n",
      "EP098_AL-1.csv\n",
      "EP101_AL-1.csv\n",
      "EP104_BL-1.csv\n",
      "ThP045_AL-2.csv\n",
      "ThP045_BL-2.csv\n",
      "ThP056_AL-2.csv\n",
      "ThP058_AL-2.csv\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "for i in listdir(\"../data/aipost\"):\n",
    "    print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split trained files and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP082_AL-1\n",
      "EP083_BL-1\n",
      "20200801S202BL-2\n",
      "EP097_AL-1\n",
      "EP084_BL-1\n",
      "EP104_BL-1\n",
      "EP081_AL-1\n",
      "EP101_AL-1\n",
      "EP098_AL-1\n",
      "20200805S200AL-1\n",
      "20200804S195AL-2\n",
      "20200619S184-2BL-1\n",
      "EP046_BL-1\n",
      "20200818S214AL-1\n",
      "20200819S221AL-1\n",
      "ThP045_AL-2\n",
      "EP081_BL-1\n",
      "ThP058_AL-2\n",
      "EP040_BL-1\n",
      "ThP045_BL-2\n",
      "EP062-AL-1\n",
      "ThP056_AL-2\n",
      "EP091_BL-1\n",
      "20200804S196AL-1\n",
      "20200705S190BL-1\n",
      "EP083_AL-1\n",
      "EP041_BL-1\n",
      "20200619S185AL-2\n",
      "20200618S183AL-1\n",
      "EP071_BL-1\n",
      "20200709S191AL-1\n",
      "EP101_AL-1\n",
      "20200619S187AL-1\n",
      "EP098_AL-1\n",
      "EP071_AL-1\n",
      "EP103_AL-1\n",
      "EP070_AL-1\n",
      "EP100_BL-1\n",
      "ThP045_AL-2\n",
      "ThP058_AL-2\n",
      "EP047_BL-1\n",
      "ThP056_AL-2\n",
      "20200623S184-2ALms1-1\n",
      "EP058-BL-1\n",
      "EP096_BL-1\n",
      "EP085_AL-1\n",
      "20200815S222BL-1\n",
      "20200819S222AL-2\n",
      "20200615S185BL-1\n",
      "EP102_AL-1\n",
      "20200709S192AL-1\n",
      "EP042_BL-1\n",
      "EP079_BL-1\n",
      "EP101_AL-1\n",
      "EP098_AL-1\n",
      "EP097_BL-1\n",
      "20200601S181BL-1\n",
      "20200807S208AL-1\n",
      "20200709S190AL-1\n",
      "20200801S200BL-2\n",
      "20200614S183BL-1\n",
      "20200817S210AL-1\n",
      "EP043_AL-1\n",
      "ThP045_AL-2\n",
      "ThP058_AL-2\n",
      "20200615S188BL-1\n",
      "EP101_BL-1\n",
      "ThP056_AL-2\n",
      "EP039_BL-1\n",
      "20200815S221BL-2\n",
      "EP072_AL-1\n",
      "20200817S211AL-1\n",
      "EP062-BL-1\n",
      "ThP049_AL-2\n",
      "EP079_AL-1\n",
      "EP078_BL-1\n",
      "20200615S187BL-1\n",
      "EP039_AL-1\n",
      "EP102_BL-1\n",
      "EP101_AL-1\n",
      "20200619S184-1BL-1\n",
      "EP098_AL-1\n",
      "ThP063_BL-2\n",
      "EP091_AL-1\n",
      "EP073_AL-1\n",
      "EP103_BL-1\n",
      "EP080_AL-2\n",
      "ThP045_AL-2\n",
      "ThP058_AL-2\n",
      "EP044_AL-1\n",
      "EP078_AL-1\n",
      "EP100_AL-1\n",
      "20200814S212BL-2\n",
      "ThP056_AL-2\n",
      "EP099_BL-1\n",
      "EP096_AL-1\n",
      "EP070_BL-1\n",
      "EP042_AL-1\n",
      "EP073_BL-1\n",
      "20200819S223AL-1\n",
      "20200605S181AL-1\n",
      "EP041_AL-1\n",
      "EP082_BL-1\n",
      "20200619S188AL-1\n",
      "EP101_AL-1\n",
      "EP098_AL-1\n",
      "20200815S223BL-2\n",
      "20200801S201BL-1\n",
      "20200623S184-1AL-1\n",
      "20200813S210BL-1\n",
      "20200804S199AL-1\n",
      "ThP045_AL-2\n",
      "20200814S214BL-1\n",
      "ThP058_AL-2\n",
      "EP104_AL-1\n",
      "EP040_AL-1\n",
      "ThP056_AL-2\n",
      "ThP056_BL-2\n",
      "20200805S202AL-2\n",
      "EP098_BL-1\n",
      "EP058-AL-1\n",
      "20200705S191BL-1\n",
      "ThP039_AL-2\n"
     ]
    }
   ],
   "source": [
    "import os,shutil\n",
    "for f in os.listdir(\"../data/finalclassifier/\"):\n",
    "    if \"files_used_for_training\" in f:\n",
    "        filename = \"../data/finalclassifier/\" + f #\"files_used_for_training.0C4JN8.csv\"  # Replace with the actual filename\n",
    "        #new folder\n",
    "        id = filename.strip().split(\"/\")[-1].split(\".\")[-2]\n",
    "        new_path = \"../data/file4pre/\"+id\n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "        string_to_extract = \"\"\n",
    "        l_t = []\n",
    "\n",
    "\n",
    "        with open(filename, \"r\") as file:\n",
    "            for line in file:\n",
    "                fields = line.strip().split(\",\")\n",
    "                string_to_extract = fields[2]\n",
    "                l_t.append(string_to_extract)\n",
    "                # print(string_to_extract)\n",
    "        a = []\n",
    "        all_path =\"C:/Users/SSG Lab/Desktop/utsn/A_128Hz4sec4stage\"\n",
    "\n",
    "        for f in os.listdir(all_path):\n",
    "            if \"raf\" in f: \n",
    "                a.append(f.strip().split(\".\")[0])\n",
    "        diff = set(a) - set(l_t)\n",
    "        for i in diff:\n",
    "            if os.path.isfile(all_path+\"/\"+i+\".csv\") : \n",
    "                print(i)   \n",
    "                shutil.copy(all_path+\"/\"+i+\".csv\",new_path+\"/\"+i+\".csv\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels for pre part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP091_BL-1\n",
      "ThP045_BL-2\n",
      "ThP045_AL-2\n",
      "20200818S214AL-1\n",
      "EP046_BL-1\n",
      "EP081_BL-1\n",
      "EP098_AL-1\n",
      "20200801S202BL-2\n",
      "EP083_BL-1\n",
      "ThP056_AL-2\n",
      "20200619S184-2BL-1\n",
      "20200804S196AL-1\n",
      "20200804S195AL-2\n",
      "EP084_BL-1\n",
      "EP101_AL-1\n",
      "20200805S200AL-1\n",
      "20200705S190BL-1\n",
      "EP081_AL-1\n",
      "EP062-AL-1\n",
      "EP082_AL-1\n",
      "EP097_AL-1\n",
      "ThP058_AL-2\n",
      "EP104_BL-1\n",
      "20200819S221AL-1\n",
      "EP040_BL-1\n",
      "20200618S183AL-1\n",
      "EP096_BL-1\n",
      "20200709S191AL-1\n",
      "ThP045_AL-2\n",
      "EP041_BL-1\n",
      "EP098_AL-1\n",
      "EP070_AL-1\n",
      "ThP056_AL-2\n",
      "20200815S222BL-1\n",
      "20200819S222AL-2\n",
      "EP103_AL-1\n",
      "20200619S185AL-2\n",
      "EP101_AL-1\n",
      "EP058-BL-1\n",
      "20200623S184-2ALms1-1\n",
      "20200619S187AL-1\n",
      "EP071_BL-1\n",
      "ThP058_AL-2\n",
      "EP085_AL-1\n",
      "EP083_AL-1\n",
      "EP047_BL-1\n",
      "EP071_AL-1\n",
      "EP100_BL-1\n",
      "EP042_BL-1\n",
      "20200709S190AL-1\n",
      "EP102_AL-1\n",
      "EP097_BL-1\n",
      "ThP045_AL-2\n",
      "EP098_AL-1\n",
      "EP072_AL-1\n",
      "EP079_BL-1\n",
      "ThP056_AL-2\n",
      "EP062-BL-1\n",
      "20200615S185BL-1\n",
      "EP043_AL-1\n",
      "20200615S188BL-1\n",
      "EP101_AL-1\n",
      "20200807S208AL-1\n",
      "20200817S210AL-1\n",
      "20200601S181BL-1\n",
      "EP101_BL-1\n",
      "20200709S192AL-1\n",
      "20200801S200BL-2\n",
      "20200817S211AL-1\n",
      "ThP058_AL-2\n",
      "20200614S183BL-1\n",
      "20200815S221BL-2\n",
      "EP039_BL-1\n",
      "EP042_AL-1\n",
      "ThP049_AL-2\n",
      "EP039_AL-1\n",
      "EP070_BL-1\n",
      "ThP045_AL-2\n",
      "EP098_AL-1\n",
      "EP096_AL-1\n",
      "EP073_AL-1\n",
      "ThP056_AL-2\n",
      "EP102_BL-1\n",
      "EP078_BL-1\n",
      "ThP063_BL-2\n",
      "EP101_AL-1\n",
      "EP103_BL-1\n",
      "20200615S187BL-1\n",
      "EP044_AL-1\n",
      "EP079_AL-1\n",
      "EP073_BL-1\n",
      "EP091_AL-1\n",
      "EP080_AL-2\n",
      "20200619S184-1BL-1\n",
      "EP099_BL-1\n",
      "EP078_AL-1\n",
      "EP100_AL-1\n",
      "ThP058_AL-2\n",
      "20200814S212BL-2\n",
      "EP098_BL-1\n",
      "20200705S191BL-1\n",
      "ThP045_AL-2\n",
      "20200814S214BL-1\n",
      "EP098_AL-1\n",
      "EP058-AL-1\n",
      "ThP056_AL-2\n",
      "EP041_AL-1\n",
      "20200801S201BL-1\n",
      "20200819S223AL-1\n",
      "20200813S210BL-1\n",
      "EP040_AL-1\n",
      "EP101_AL-1\n",
      "EP104_AL-1\n",
      "20200619S188AL-1\n",
      "20200805S202AL-2\n",
      "ThP039_AL-2\n",
      "20200815S223BL-2\n",
      "20200804S199AL-1\n",
      "EP082_BL-1\n",
      "20200605S181AL-1\n",
      "ThP058_AL-2\n",
      "ThP056_BL-2\n",
      "20200623S184-1AL-1\n"
     ]
    }
   ],
   "source": [
    "import os,shutil\n",
    "for f in os.listdir(\"../data/finalclassifier/\"):\n",
    "    if \"files_used_for_training\" in f:\n",
    "        filename = \"../data/finalclassifier/\" + f #\"files_used_for_training.0C4JN8.csv\"  # Replace with the actual filename\n",
    "        #new folder\n",
    "        id = filename.strip().split(\"/\")[-1].split(\".\")[-2]\n",
    "        new_path = \"../data/label4pre/\"+id\n",
    "        if not os.path.exists(new_path):\n",
    "            os.makedirs(new_path)\n",
    "        string_to_extract = \"\"\n",
    "        l_t = []\n",
    "\n",
    "\n",
    "        with open(filename, \"r\") as file:\n",
    "            for line in file:\n",
    "                fields = line.strip().split(\",\")\n",
    "                string_to_extract = fields[2]\n",
    "                l_t.append(string_to_extract)\n",
    "                # print(string_to_extract)\n",
    "        a = []\n",
    "        all_path =\"C:/Users/SSG Lab/Desktop/utsn/A_128Hz4sec4stage\"\n",
    "\n",
    "        for f in os.listdir(all_path):\n",
    "            if \"raf\" in f: \n",
    "                a.append(f.strip().split(\".\")[0])\n",
    "        diff = set(a) - set(l_t)\n",
    "        for i in diff:\n",
    "            if os.path.isfile(all_path+\"/\"+i+\"_Trend.csv\") : \n",
    "                print(i)   \n",
    "                shutil.copy(all_path+\"/\"+i+\"_Trend.csv\",new_path+\"/\"+i+\"_Trend.csv\")\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.insert(0,\"..\")\n",
    "print(sys.path)\n",
    "print(\"---------------------------------------------------------\")\n",
    "from _7utils.dataReader import DataReader\n",
    "import matplotlib.pyplot as plt\n",
    "dataReader = DataReader()\n",
    "# dataReader.readAll(sys)\n",
    "#readOfflineEEGandStageLabels2pickle.py reads text files containing EEG raw data signals and ground truth stage labels from the WAVEDIR directory. It writes files starting with \"eegAndStage\" into the \"data/pickled\" directory. These files are in Python's pickle format to enable faster access.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = {\"a\":1,\"b\":2,\"c\":3}\n",
    "ls = [3,2,4,6]\n",
    "ls[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data,m, t = dataReader.readEEG(\"../data/sampledata/Raw/D1798_short.txt\")\n",
    "data = np.array(data).reshape(1, -1)      \n",
    "# raw = mne.io.RawArray(data, inf)      \n",
    "data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stft-freqs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "eegSegment = data[0][:128*4]\n",
    "samplingFreq = 128\n",
    "stft_nperseg = 256\n",
    "freqs, segment_times, Zxx = signal.stft(\n",
    "    eegSegment, fs=samplingFreq, nperseg=stft_nperseg)\n",
    "\n",
    "\n",
    "def filtering(Zxx, freqs, lowerFreq, upperFreq):\n",
    "    zipped = list(filter(lambda x: lowerFreq <=\n",
    "                         x[1] and x[1] < upperFreq, zip(Zxx, freqs)))\n",
    "    return np.array([e[0] for e in zipped]), np.array([e[1] for e in zipped])\n",
    "\n",
    "\n",
    "Zxx_filtered, f = filtering(Zxx, freqs, 1, 12)\n",
    "\n",
    "\n",
    "BandWidth = 11\n",
    "binWidth4freqHisto = 0.5\n",
    "\n",
    "freqBinNum = round(BandWidth / binWidth4freqHisto)\n",
    "binSize = np.int(np.floor(1.0 * len(Zxx) / freqBinNum))\n",
    "\n",
    "Zxx_binned = np.array([np.sum(np.abs(\n",
    "    Zxx_filtered[(binID*binSize):((binID+1)*binSize)]), axis=0) for binID in range(freqBinNum)])\n",
    "\n",
    "plt.pcolormesh(segment_times, f, Zxx_binned)\n",
    "# plt.pcolormesh(segment_times, f, Zxx_binned, shading='gouraud')\n",
    "plt.title('STFT Magnitude')\n",
    "plt.ylabel('Bin')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zxx_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BandWidth = 11\n",
    "binWidth4freqHisto = 0.5\n",
    "\n",
    "\n",
    "freqBinNum = round(BandWidth / binWidth4freqHisto) \n",
    "binSize = np.int(np.floor(1.0 * len(Zxx) / freqBinNum))\n",
    "\n",
    "Zxx_binned = np.array([np.sum(np.abs(\n",
    "    Zxx_filtered[(binID*binSize):((binID+1)*binSize)]), axis=0) for binID in range(freqBinNum)])\n",
    "Zxx_binned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolormesh(segment_times, f, Zxx_binned)\n",
    "# plt.pcolormesh(segment_times, f, Zxx_binned, shading='gouraud')\n",
    "plt.title('STFT Magnitude')\n",
    "plt.ylabel('Bin')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "\n",
    "eegSegment = data[0][:128*4]\n",
    "sfreq = 128\n",
    "nperseg = 256\n",
    "\n",
    "# Create MNE RawArray object from EEG data\n",
    "raw = mne.io.RawArray(eegSegment.reshape(1, -1), info=mne.create_info(['EEG'], sfreq, 'eeg'))\n",
    "raw.compute_psd(fmin =1,fmax =12).get_data()#.plot()\n",
    "# raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "\n",
    "eegSegment = data[0][:128*4]\n",
    "sfreq = 128\n",
    "nperseg = 256\n",
    "\n",
    "# Create MNE RawArray object from EEG data\n",
    "# raw = mne.io.RawArray(eegSegment.reshape(1, -1), info=mne.create_info(ch_names=['EEG'], sfreq=sfreq))\n",
    "seg = eegSegment.reshape((1,-1))\n",
    "seg.shape\n",
    "# Apply STFT\n",
    "frequencies = mne.time_frequency.stft(seg, wsize=nperseg)\n",
    "fr = frequencies[0]\n",
    "f = np.sum(abs(fr),axis = 1)\n",
    "plt.plot(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.pcolormesh(segment_times, freqs, np.abs(Zxx),  # shading='gouraud'\n",
    "               )\n",
    "plt.title('STFT Magnitude')\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "# plt.ylim(fmin, fmax)\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtering(Zxx, freqs, lowerFreq, upperFreq):\n",
    "        zipped = list(filter(lambda x: lowerFreq <=\n",
    "                      x[1] and x[1] < upperFreq, zip(Zxx, freqs)))\n",
    "        return np.array([e[0] for e in zipped]), np.array([e[1] for e in zipped])\n",
    "\n",
    "def binning(Zxx, freqs, freqBinNum):\n",
    "    binSize = np.int(np.floor(1.0 * len(Zxx) / freqBinNum))\n",
    "    Zxx_binned = np.array([np.sum(np.abs(Zxx[(binID*binSize):((binID+1)*binSize)]),axis=0) for binID in range(freqBinNum)])\n",
    "    freqs_binned = np.array([np.mean(freqs[(binID*binSize):((binID+1)*binSize)],axis=0) for binID in range(freqBinNum)])\n",
    "    return Zxx_binned, freqs_binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [i for i in range(5)]\n",
    "print(a[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHot2stageLabel(oneHot, stageLabels4evaluation, stageLabel2stageID):\n",
    "    # print('in oneHot2stageLabel, oneHot.shape = ' + str(oneHot.shape))\n",
    "    # keyList = [keys for keys in params.stageLabel2stageID.keys()]\n",
    "    # print('keyList = ' + str(keyList))\n",
    "    stageID = np.argmax(oneHot)\n",
    "    for key in stageLabels4evaluation:\n",
    "        if stageLabel2stageID[key] == stageID:\n",
    "            return key\n",
    "    return '-'\n",
    "\n",
    "labelCorrectionDict = {'S' : 'n', 'W' : 'w', 'R' : 'r', 'H' :'h', 'RW' : 'w', 'M' : 'm', 'P' : 'P', 'F2' : 'F2', '?' : '?', '-' : '-'}\n",
    "\n",
    "stageLabels4evaluation = orig_stageLabels[:self.maximumStageNum]\n",
    "stageLabel2stageID = {stage: stageID for stage, stageID in zip(\n",
    "    orig_stageLabels[:self.maximumStageNum], range(self.maximumStageNum))}\n",
    "\n",
    "def correct_label(items):\n",
    "    return labelCorrectionDict[oneHot2stageLabel(items[0], stageLabels4evaluation, stageLabel2stageID)]\n",
    "\n",
    "if self.params.classifierType == 'deep':\n",
    "    if type(y_pred_modified) != list and type(y_pred_modified) != np.ndarray:\n",
    "        if y_pred_modified == '?':\n",
    "            y_pred = y_pred_modified\n",
    "        else:\n",
    "            y_pred = correct_label(y_pred_modified)\n",
    "    else:\n",
    "        y_pred = correct_label(y_pred_modified)\n",
    "    # print('after labelCorrection, y_pred =', y_pred)\n",
    "    # print('y_pred = ' + str(y_pred))\n",
    "else:\n",
    "    y_pred = self.params.labelCorrectionDict[y_pred_modified[0]]\n",
    "\n",
    "# print(y_pred, end='')\n",
    "self.pastStages_L.append(y_pred_modified[0])\n",
    "return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelCorrectionDict = {'S': 'n', 'W': 'w', 'R': 'r', 'H': 'h',\n",
    "                       'RW': 'w', 'M': 'm', 'P': 'P', 'F2': 'F2', '?': '?', '-': '-'}\n",
    "labelCorrectionDict['H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,3,5,6,7,11,3,66]\n",
    "import numpy as np\n",
    "np.argmax(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
